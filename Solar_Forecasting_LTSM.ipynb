{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2e4cae-3884-4807-bea5-39282bf8310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1994/1994 - 3s - loss: 0.0350 - 3s/epoch - 1ms/step\n",
      "Epoch 2/100\n",
      "1994/1994 - 2s - loss: 0.0322 - 2s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "1994/1994 - 2s - loss: 0.0316 - 2s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "1994/1994 - 2s - loss: 0.0316 - 2s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "1994/1994 - 2s - loss: 0.0313 - 2s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "1994/1994 - 2s - loss: 0.0311 - 2s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "1994/1994 - 2s - loss: 0.0307 - 2s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "1994/1994 - 2s - loss: 0.0307 - 2s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "1994/1994 - 2s - loss: 0.0309 - 2s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "1994/1994 - 2s - loss: 0.0308 - 2s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "1994/1994 - 2s - loss: 0.0305 - 2s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "1994/1994 - 2s - loss: 0.0308 - 2s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "1994/1994 - 2s - loss: 0.0306 - 2s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "1994/1994 - 2s - loss: 0.0306 - 2s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "1994/1994 - 2s - loss: 0.0303 - 2s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "1994/1994 - 2s - loss: 0.0303 - 2s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "1994/1994 - 2s - loss: 0.0303 - 2s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "1994/1994 - 2s - loss: 0.0301 - 2s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "1994/1994 - 2s - loss: 0.0302 - 2s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "1994/1994 - 2s - loss: 0.0299 - 2s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "1994/1994 - 2s - loss: 0.0301 - 2s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "1994/1994 - 2s - loss: 0.0298 - 2s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "1994/1994 - 2s - loss: 0.0299 - 2s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "1994/1994 - 2s - loss: 0.0299 - 2s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "1994/1994 - 2s - loss: 0.0297 - 2s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "1994/1994 - 2s - loss: 0.0297 - 2s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "1994/1994 - 2s - loss: 0.0294 - 2s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "1994/1994 - 2s - loss: 0.0294 - 2s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "1994/1994 - 2s - loss: 0.0295 - 2s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "1994/1994 - 2s - loss: 0.0295 - 2s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "1994/1994 - 2s - loss: 0.0292 - 2s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "1994/1994 - 2s - loss: 0.0292 - 2s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "1994/1994 - 2s - loss: 0.0291 - 2s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "1994/1994 - 2s - loss: 0.0292 - 2s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "1994/1994 - 2s - loss: 0.0289 - 2s/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "1994/1994 - 2s - loss: 0.0290 - 2s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "1994/1994 - 2s - loss: 0.0292 - 2s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "1994/1994 - 2s - loss: 0.0289 - 2s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "1994/1994 - 2s - loss: 0.0288 - 2s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "1994/1994 - 2s - loss: 0.0289 - 2s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "1994/1994 - 2s - loss: 0.0289 - 2s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "1994/1994 - 2s - loss: 0.0288 - 2s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "1994/1994 - 2s - loss: 0.0289 - 2s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "1994/1994 - 2s - loss: 0.0288 - 2s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "1994/1994 - 2s - loss: 0.0288 - 2s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "1994/1994 - 2s - loss: 0.0287 - 2s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "1994/1994 - 2s - loss: 0.0286 - 2s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "1994/1994 - 2s - loss: 0.0285 - 2s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "1994/1994 - 2s - loss: 0.0284 - 2s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "1994/1994 - 2s - loss: 0.0284 - 2s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "1994/1994 - 2s - loss: 0.0280 - 2s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "1994/1994 - 2s - loss: 0.0283 - 2s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "1994/1994 - 2s - loss: 0.0279 - 2s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "1994/1994 - 2s - loss: 0.0280 - 2s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "1994/1994 - 2s - loss: 0.0279 - 2s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "1994/1994 - 2s - loss: 0.0278 - 2s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "1994/1994 - 2s - loss: 0.0277 - 2s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "1994/1994 - 2s - loss: 0.0275 - 2s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "1994/1994 - 2s - loss: 0.0275 - 2s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "1994/1994 - 2s - loss: 0.0272 - 2s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "1994/1994 - 2s - loss: 0.0274 - 2s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "1994/1994 - 2s - loss: 0.0270 - 2s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "1994/1994 - 2s - loss: 0.0272 - 2s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "1994/1994 - 2s - loss: 0.0268 - 2s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "1994/1994 - 2s - loss: 0.0268 - 2s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "1994/1994 - 2s - loss: 0.0267 - 2s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "1994/1994 - 2s - loss: 0.0264 - 2s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "1994/1994 - 2s - loss: 0.0263 - 2s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "1994/1994 - 2s - loss: 0.0258 - 2s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "1994/1994 - 2s - loss: 0.0255 - 2s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "1994/1994 - 2s - loss: 0.0255 - 2s/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "1994/1994 - 2s - loss: 0.0252 - 2s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "1994/1994 - 2s - loss: 0.0252 - 2s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "1994/1994 - 2s - loss: 0.0245 - 2s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "1994/1994 - 2s - loss: 0.0246 - 2s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "1994/1994 - 2s - loss: 0.0243 - 2s/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "1994/1994 - 2s - loss: 0.0242 - 2s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "1994/1994 - 2s - loss: 0.0241 - 2s/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "1994/1994 - 2s - loss: 0.0238 - 2s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "1994/1994 - 2s - loss: 0.0237 - 2s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "1994/1994 - 2s - loss: 0.0230 - 2s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "1994/1994 - 2s - loss: 0.0232 - 2s/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "1994/1994 - 2s - loss: 0.0232 - 2s/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "1994/1994 - 2s - loss: 0.0229 - 2s/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "1994/1994 - 2s - loss: 0.0225 - 2s/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "1994/1994 - 2s - loss: 0.0221 - 2s/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "1994/1994 - 2s - loss: 0.0222 - 2s/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "1994/1994 - 2s - loss: 0.0218 - 2s/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "1994/1994 - 2s - loss: 0.0216 - 2s/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "1994/1994 - 2s - loss: 0.0215 - 2s/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "1994/1994 - 2s - loss: 0.0209 - 2s/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "1994/1994 - 2s - loss: 0.0208 - 2s/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "1994/1994 - 2s - loss: 0.0205 - 2s/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "1994/1994 - 2s - loss: 0.0204 - 2s/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "1994/1994 - 2s - loss: 0.0198 - 2s/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "1994/1994 - 2s - loss: 0.0199 - 2s/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "1994/1994 - 2s - loss: 0.0197 - 2s/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "1994/1994 - 2s - loss: 0.0195 - 2s/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "1994/1994 - 2s - loss: 0.0188 - 2s/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "1994/1994 - 2s - loss: 0.0189 - 2s/epoch - 1ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Root Mean Squared Error (RMSE): 3.59\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Forecast for PolyPwr (Yn+1): 8.60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('Pasion et al dataset.csv')\n",
    "data = df[df['Location'] == 'Hill Weber']\n",
    "data = df[df['Time'] == 1000]\n",
    "\n",
    "data = data[['Date', 'PolyPwr']] \n",
    "data.rename(columns={'Date': 'ds', 'PolyPwr': 'y'}, inplace=True)\n",
    "\n",
    "data['ds'] = pd.to_datetime(data['ds'])\n",
    "data.set_index('ds', inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "look_back = 20  \n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - look_back):\n",
    "    X.append(data_scaled[i:i+look_back])\n",
    "    y.append(data_scaled[i+look_back])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "last_observed = X_test[-1].reshape(1, look_back, 1)\n",
    "\n",
    "forecast_value = model.predict(last_observed)\n",
    "forecast_value = scaler.inverse_transform(forecast_value)[0][0]\n",
    "print(f\"Forecast for PolyPwr (Yn+1): {forecast_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d68b7a-533a-40a8-8951-3da44eeb3c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2178/2178 - 3s - loss: 0.0325 - 3s/epoch - 1ms/step\n",
      "Epoch 2/100\n",
      "2178/2178 - 2s - loss: 0.0298 - 2s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "2178/2178 - 2s - loss: 0.0297 - 2s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "2178/2178 - 2s - loss: 0.0295 - 2s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "2178/2178 - 2s - loss: 0.0295 - 2s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "2178/2178 - 2s - loss: 0.0292 - 2s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "2178/2178 - 2s - loss: 0.0291 - 2s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "2178/2178 - 2s - loss: 0.0293 - 2s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "2178/2178 - 2s - loss: 0.0290 - 2s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "2178/2178 - 2s - loss: 0.0288 - 2s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "2178/2178 - 2s - loss: 0.0289 - 2s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "2178/2178 - 2s - loss: 0.0288 - 2s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "2178/2178 - 3s - loss: 0.0288 - 3s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "2178/2178 - 3s - loss: 0.0286 - 3s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "2178/2178 - 3s - loss: 0.0288 - 3s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "2178/2178 - 2s - loss: 0.0287 - 2s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "2178/2178 - 2s - loss: 0.0282 - 2s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "2178/2178 - 3s - loss: 0.0282 - 3s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "2178/2178 - 3s - loss: 0.0282 - 3s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "2178/2178 - 2s - loss: 0.0282 - 2s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "2178/2178 - 2s - loss: 0.0280 - 2s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "2178/2178 - 2s - loss: 0.0280 - 2s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "2178/2178 - 3s - loss: 0.0283 - 3s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "2178/2178 - 2s - loss: 0.0279 - 2s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "2178/2178 - 2s - loss: 0.0278 - 2s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "2178/2178 - 2s - loss: 0.0278 - 2s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "2178/2178 - 2s - loss: 0.0277 - 2s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "2178/2178 - 2s - loss: 0.0276 - 2s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "2178/2178 - 2s - loss: 0.0277 - 2s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "2178/2178 - 3s - loss: 0.0277 - 3s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "2178/2178 - 2s - loss: 0.0274 - 2s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "2178/2178 - 2s - loss: 0.0273 - 2s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "2178/2178 - 2s - loss: 0.0273 - 2s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "2178/2178 - 3s - loss: 0.0276 - 3s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "2178/2178 - 3s - loss: 0.0272 - 3s/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "2178/2178 - 2s - loss: 0.0274 - 2s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "2178/2178 - 2s - loss: 0.0272 - 2s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "2178/2178 - 3s - loss: 0.0273 - 3s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "2178/2178 - 3s - loss: 0.0274 - 3s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "2178/2178 - 3s - loss: 0.0271 - 3s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "2178/2178 - 2s - loss: 0.0271 - 2s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "2178/2178 - 2s - loss: 0.0271 - 2s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "2178/2178 - 2s - loss: 0.0270 - 2s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "2178/2178 - 3s - loss: 0.0268 - 3s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "2178/2178 - 2s - loss: 0.0269 - 2s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "2178/2178 - 2s - loss: 0.0268 - 2s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "2178/2178 - 2s - loss: 0.0269 - 2s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "2178/2178 - 2s - loss: 0.0268 - 2s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "2178/2178 - 2s - loss: 0.0267 - 2s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "2178/2178 - 2s - loss: 0.0266 - 2s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "2178/2178 - 2s - loss: 0.0265 - 2s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "2178/2178 - 2s - loss: 0.0265 - 2s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "2178/2178 - 2s - loss: 0.0264 - 2s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "2178/2178 - 2s - loss: 0.0264 - 2s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "2178/2178 - 2s - loss: 0.0260 - 2s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "2178/2178 - 2s - loss: 0.0262 - 2s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "2178/2178 - 2s - loss: 0.0258 - 2s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "2178/2178 - 2s - loss: 0.0257 - 2s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "2178/2178 - 2s - loss: 0.0256 - 2s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "2178/2178 - 2s - loss: 0.0254 - 2s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "2178/2178 - 2s - loss: 0.0254 - 2s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "2178/2178 - 2s - loss: 0.0252 - 2s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "2178/2178 - 2s - loss: 0.0253 - 2s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "2178/2178 - 2s - loss: 0.0249 - 2s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "2178/2178 - 2s - loss: 0.0248 - 2s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "2178/2178 - 2s - loss: 0.0245 - 2s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "2178/2178 - 2s - loss: 0.0244 - 2s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "2178/2178 - 2s - loss: 0.0239 - 2s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "2178/2178 - 2s - loss: 0.0243 - 2s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "2178/2178 - 2s - loss: 0.0238 - 2s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "2178/2178 - 2s - loss: 0.0239 - 2s/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "2178/2178 - 2s - loss: 0.0237 - 2s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "2178/2178 - 2s - loss: 0.0234 - 2s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "2178/2178 - 3s - loss: 0.0234 - 3s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "2178/2178 - 3s - loss: 0.0234 - 3s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "2178/2178 - 3s - loss: 0.0235 - 3s/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "2178/2178 - 3s - loss: 0.0227 - 3s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "2178/2178 - 2s - loss: 0.0227 - 2s/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "2178/2178 - 3s - loss: 0.0226 - 3s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "2178/2178 - 3s - loss: 0.0220 - 3s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "2178/2178 - 3s - loss: 0.0220 - 3s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "2178/2178 - 2s - loss: 0.0217 - 2s/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "2178/2178 - 2s - loss: 0.0218 - 2s/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "2178/2178 - 2s - loss: 0.0212 - 2s/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "2178/2178 - 2s - loss: 0.0209 - 2s/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "2178/2178 - 2s - loss: 0.0212 - 2s/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "2178/2178 - 3s - loss: 0.0205 - 3s/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "2178/2178 - 2s - loss: 0.0204 - 2s/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "2178/2178 - 3s - loss: 0.0201 - 3s/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "2178/2178 - 2s - loss: 0.0196 - 2s/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "2178/2178 - 3s - loss: 0.0203 - 3s/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "2178/2178 - 2s - loss: 0.0195 - 2s/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "2178/2178 - 2s - loss: 0.0190 - 2s/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "2178/2178 - 2s - loss: 0.0190 - 2s/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "2178/2178 - 2s - loss: 0.0185 - 2s/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "2178/2178 - 2s - loss: 0.0185 - 2s/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "2178/2178 - 2s - loss: 0.0182 - 2s/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "2178/2178 - 2s - loss: 0.0176 - 2s/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "2178/2178 - 2s - loss: 0.0175 - 2s/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "2178/2178 - 2s - loss: 0.0173 - 2s/epoch - 1ms/step\n",
      "18/18 [==============================] - 0s 861us/step\n",
      "Root Mean Squared Error (RMSE): 4.18\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Forecast for PolyPwr (Yn+1): 14.84\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('Pasion et al dataset.csv')\n",
    "data = df[df['Location'] == 'Hill Weber']\n",
    "data = df[df['Time'] == 1100]\n",
    "\n",
    "data = data[['Date', 'PolyPwr']] \n",
    "data.rename(columns={'Date': 'ds', 'PolyPwr': 'y'}, inplace=True)\n",
    "\n",
    "data['ds'] = pd.to_datetime(data['ds'])\n",
    "data.set_index('ds', inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "look_back = 20  \n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - look_back):\n",
    "    X.append(data_scaled[i:i+look_back])\n",
    "    y.append(data_scaled[i+look_back])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "last_observed = X_test[-1].reshape(1, look_back, 1)\n",
    "\n",
    "forecast_value = model.predict(last_observed)\n",
    "forecast_value = scaler.inverse_transform(forecast_value)[0][0]\n",
    "print(f\"Forecast for PolyPwr (Yn+1): {forecast_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518f11c3-3346-4d8e-baf6-1afee943997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2411/2411 - 3s - loss: 0.0331 - 3s/epoch - 1ms/step\n",
      "Epoch 2/100\n",
      "2411/2411 - 3s - loss: 0.0323 - 3s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "2411/2411 - 3s - loss: 0.0318 - 3s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "2411/2411 - 3s - loss: 0.0316 - 3s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "2411/2411 - 3s - loss: 0.0316 - 3s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "2411/2411 - 3s - loss: 0.0315 - 3s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "2411/2411 - 3s - loss: 0.0313 - 3s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "2411/2411 - 3s - loss: 0.0312 - 3s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "2411/2411 - 3s - loss: 0.0313 - 3s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "2411/2411 - 3s - loss: 0.0311 - 3s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "2411/2411 - 3s - loss: 0.0310 - 3s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "2411/2411 - 3s - loss: 0.0308 - 3s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "2411/2411 - 3s - loss: 0.0310 - 3s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "2411/2411 - 3s - loss: 0.0309 - 3s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "2411/2411 - 3s - loss: 0.0308 - 3s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "2411/2411 - 3s - loss: 0.0306 - 3s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "2411/2411 - 3s - loss: 0.0307 - 3s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "2411/2411 - 3s - loss: 0.0306 - 3s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "2411/2411 - 3s - loss: 0.0306 - 3s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "2411/2411 - 3s - loss: 0.0304 - 3s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "2411/2411 - 3s - loss: 0.0304 - 3s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "2411/2411 - 3s - loss: 0.0303 - 3s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "2411/2411 - 3s - loss: 0.0304 - 3s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "2411/2411 - 3s - loss: 0.0303 - 3s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "2411/2411 - 3s - loss: 0.0302 - 3s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "2411/2411 - 3s - loss: 0.0300 - 3s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "2411/2411 - 3s - loss: 0.0299 - 3s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "2411/2411 - 3s - loss: 0.0299 - 3s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "2411/2411 - 3s - loss: 0.0299 - 3s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "2411/2411 - 3s - loss: 0.0299 - 3s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "2411/2411 - 3s - loss: 0.0299 - 3s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "2411/2411 - 3s - loss: 0.0298 - 3s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "2411/2411 - 3s - loss: 0.0299 - 3s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "2411/2411 - 3s - loss: 0.0296 - 3s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "2411/2411 - 3s - loss: 0.0296 - 3s/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "2411/2411 - 3s - loss: 0.0295 - 3s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "2411/2411 - 3s - loss: 0.0295 - 3s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "2411/2411 - 3s - loss: 0.0294 - 3s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "2411/2411 - 3s - loss: 0.0289 - 3s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "2411/2411 - 3s - loss: 0.0295 - 3s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "2411/2411 - 3s - loss: 0.0291 - 3s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "2411/2411 - 3s - loss: 0.0292 - 3s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "2411/2411 - 3s - loss: 0.0291 - 3s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "2411/2411 - 3s - loss: 0.0290 - 3s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "2411/2411 - 3s - loss: 0.0292 - 3s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "2411/2411 - 3s - loss: 0.0291 - 3s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "2411/2411 - 3s - loss: 0.0292 - 3s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "2411/2411 - 3s - loss: 0.0286 - 3s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "2411/2411 - 3s - loss: 0.0289 - 3s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "2411/2411 - 3s - loss: 0.0287 - 3s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "2411/2411 - 3s - loss: 0.0286 - 3s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "2411/2411 - 3s - loss: 0.0286 - 3s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "2411/2411 - 3s - loss: 0.0286 - 3s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "2411/2411 - 3s - loss: 0.0285 - 3s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "2411/2411 - 3s - loss: 0.0284 - 3s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "2411/2411 - 3s - loss: 0.0284 - 3s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "2411/2411 - 3s - loss: 0.0285 - 3s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "2411/2411 - 3s - loss: 0.0284 - 3s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "2411/2411 - 3s - loss: 0.0282 - 3s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "2411/2411 - 3s - loss: 0.0281 - 3s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "2411/2411 - 3s - loss: 0.0282 - 3s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "2411/2411 - 3s - loss: 0.0279 - 3s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "2411/2411 - 3s - loss: 0.0278 - 3s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "2411/2411 - 3s - loss: 0.0280 - 3s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "2411/2411 - 3s - loss: 0.0278 - 3s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "2411/2411 - 3s - loss: 0.0276 - 3s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "2411/2411 - 3s - loss: 0.0273 - 3s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "2411/2411 - 3s - loss: 0.0272 - 3s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "2411/2411 - 3s - loss: 0.0273 - 3s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "2411/2411 - 3s - loss: 0.0271 - 3s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "2411/2411 - 3s - loss: 0.0271 - 3s/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "2411/2411 - 3s - loss: 0.0269 - 3s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "2411/2411 - 3s - loss: 0.0271 - 3s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "2411/2411 - 3s - loss: 0.0267 - 3s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "2411/2411 - 3s - loss: 0.0267 - 3s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "2411/2411 - 3s - loss: 0.0263 - 3s/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "2411/2411 - 3s - loss: 0.0269 - 3s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "2411/2411 - 3s - loss: 0.0265 - 3s/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "2411/2411 - 3s - loss: 0.0258 - 3s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "2411/2411 - 3s - loss: 0.0261 - 3s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "2411/2411 - 3s - loss: 0.0256 - 3s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "2411/2411 - 3s - loss: 0.0253 - 3s/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "2411/2411 - 3s - loss: 0.0255 - 3s/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "2411/2411 - 3s - loss: 0.0252 - 3s/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "2411/2411 - 3s - loss: 0.0252 - 3s/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "2411/2411 - 3s - loss: 0.0246 - 3s/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "2411/2411 - 3s - loss: 0.0243 - 3s/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "2411/2411 - 3s - loss: 0.0243 - 3s/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "2411/2411 - 3s - loss: 0.0241 - 3s/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "2411/2411 - 3s - loss: 0.0242 - 3s/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "2411/2411 - 3s - loss: 0.0240 - 3s/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "2411/2411 - 3s - loss: 0.0240 - 3s/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "2411/2411 - 3s - loss: 0.0238 - 3s/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "2411/2411 - 3s - loss: 0.0237 - 3s/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "2411/2411 - 3s - loss: 0.0235 - 3s/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "2411/2411 - 3s - loss: 0.0234 - 3s/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "2411/2411 - 3s - loss: 0.0233 - 3s/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "2411/2411 - 3s - loss: 0.0229 - 3s/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "2411/2411 - 3s - loss: 0.0229 - 3s/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "2411/2411 - 3s - loss: 0.0233 - 3s/epoch - 1ms/step\n",
      "19/19 [==============================] - 0s 892us/step\n",
      "Root Mean Squared Error (RMSE): 5.04\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Forecast for PolyPwr (Yn+1): 14.09\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('Pasion et al dataset.csv')\n",
    "data = df[df['Location'] == 'Hill Weber']\n",
    "data = df[df['Time'] == 1200]\n",
    "\n",
    "data = data[['Date', 'PolyPwr']] \n",
    "data.rename(columns={'Date': 'ds', 'PolyPwr': 'y'}, inplace=True)\n",
    "\n",
    "data['ds'] = pd.to_datetime(data['ds'])\n",
    "data.set_index('ds', inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "look_back = 20  \n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - look_back):\n",
    "    X.append(data_scaled[i:i+look_back])\n",
    "    y.append(data_scaled[i+look_back])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "last_observed = X_test[-1].reshape(1, look_back, 1)\n",
    "\n",
    "forecast_value = model.predict(last_observed)\n",
    "forecast_value = scaler.inverse_transform(forecast_value)[0][0]\n",
    "print(f\"Forecast for PolyPwr (Yn+1): {forecast_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe639570-74e3-4074-8005-ccf226c49045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2518/2518 - 3s - loss: 0.0352 - 3s/epoch - 1ms/step\n",
      "Epoch 2/100\n",
      "2518/2518 - 3s - loss: 0.0340 - 3s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "2518/2518 - 3s - loss: 0.0333 - 3s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "2518/2518 - 3s - loss: 0.0332 - 3s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "2518/2518 - 3s - loss: 0.0329 - 3s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "2518/2518 - 3s - loss: 0.0333 - 3s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "2518/2518 - 3s - loss: 0.0329 - 3s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "2518/2518 - 3s - loss: 0.0331 - 3s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "2518/2518 - 3s - loss: 0.0328 - 3s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "2518/2518 - 3s - loss: 0.0329 - 3s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "2518/2518 - 3s - loss: 0.0328 - 3s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "2518/2518 - 3s - loss: 0.0328 - 3s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "2518/2518 - 3s - loss: 0.0326 - 3s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "2518/2518 - 3s - loss: 0.0325 - 3s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "2518/2518 - 3s - loss: 0.0323 - 3s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "2518/2518 - 3s - loss: 0.0323 - 3s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "2518/2518 - 3s - loss: 0.0322 - 3s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "2518/2518 - 3s - loss: 0.0322 - 3s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "2518/2518 - 3s - loss: 0.0321 - 3s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "2518/2518 - 3s - loss: 0.0321 - 3s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "2518/2518 - 3s - loss: 0.0319 - 3s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "2518/2518 - 3s - loss: 0.0318 - 3s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "2518/2518 - 3s - loss: 0.0320 - 3s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "2518/2518 - 3s - loss: 0.0318 - 3s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "2518/2518 - 3s - loss: 0.0318 - 3s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "2518/2518 - 3s - loss: 0.0318 - 3s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "2518/2518 - 3s - loss: 0.0317 - 3s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "2518/2518 - 3s - loss: 0.0317 - 3s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "2518/2518 - 3s - loss: 0.0317 - 3s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "2518/2518 - 3s - loss: 0.0316 - 3s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "2518/2518 - 3s - loss: 0.0314 - 3s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "2518/2518 - 3s - loss: 0.0316 - 3s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "2518/2518 - 3s - loss: 0.0313 - 3s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "2518/2518 - 3s - loss: 0.0315 - 3s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "2518/2518 - 3s - loss: 0.0312 - 3s/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "2518/2518 - 3s - loss: 0.0310 - 3s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "2518/2518 - 3s - loss: 0.0311 - 3s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "2518/2518 - 3s - loss: 0.0310 - 3s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "2518/2518 - 3s - loss: 0.0310 - 3s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "2518/2518 - 3s - loss: 0.0309 - 3s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "2518/2518 - 3s - loss: 0.0309 - 3s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "2518/2518 - 3s - loss: 0.0309 - 3s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "2518/2518 - 3s - loss: 0.0308 - 3s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "2518/2518 - 3s - loss: 0.0308 - 3s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "2518/2518 - 3s - loss: 0.0305 - 3s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "2518/2518 - 3s - loss: 0.0308 - 3s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "2518/2518 - 3s - loss: 0.0306 - 3s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "2518/2518 - 3s - loss: 0.0307 - 3s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "2518/2518 - 3s - loss: 0.0304 - 3s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "2518/2518 - 3s - loss: 0.0304 - 3s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "2518/2518 - 3s - loss: 0.0303 - 3s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "2518/2518 - 3s - loss: 0.0302 - 3s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "2518/2518 - 3s - loss: 0.0300 - 3s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "2518/2518 - 3s - loss: 0.0301 - 3s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "2518/2518 - 3s - loss: 0.0302 - 3s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "2518/2518 - 3s - loss: 0.0300 - 3s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "2518/2518 - 3s - loss: 0.0299 - 3s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "2518/2518 - 3s - loss: 0.0294 - 3s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "2518/2518 - 3s - loss: 0.0297 - 3s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "2518/2518 - 3s - loss: 0.0292 - 3s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "2518/2518 - 3s - loss: 0.0294 - 3s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "2518/2518 - 3s - loss: 0.0292 - 3s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "2518/2518 - 3s - loss: 0.0289 - 3s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "2518/2518 - 3s - loss: 0.0288 - 3s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "2518/2518 - 3s - loss: 0.0288 - 3s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "2518/2518 - 3s - loss: 0.0284 - 3s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "2518/2518 - 3s - loss: 0.0293 - 3s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "2518/2518 - 3s - loss: 0.0281 - 3s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "2518/2518 - 3s - loss: 0.0281 - 3s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "2518/2518 - 3s - loss: 0.0279 - 3s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "2518/2518 - 3s - loss: 0.0276 - 3s/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "2518/2518 - 3s - loss: 0.0273 - 3s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "2518/2518 - 3s - loss: 0.0271 - 3s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "2518/2518 - 3s - loss: 0.0269 - 3s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "2518/2518 - 3s - loss: 0.0268 - 3s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "2518/2518 - 3s - loss: 0.0266 - 3s/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "2518/2518 - 3s - loss: 0.0262 - 3s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "2518/2518 - 3s - loss: 0.0257 - 3s/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "2518/2518 - 3s - loss: 0.0259 - 3s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "2518/2518 - 3s - loss: 0.0253 - 3s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "2518/2518 - 3s - loss: 0.0257 - 3s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "2518/2518 - 3s - loss: 0.0249 - 3s/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "2518/2518 - 3s - loss: 0.0248 - 3s/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "2518/2518 - 3s - loss: 0.0246 - 3s/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "2518/2518 - 3s - loss: 0.0243 - 3s/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "2518/2518 - 3s - loss: 0.0239 - 3s/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "2518/2518 - 3s - loss: 0.0236 - 3s/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "2518/2518 - 3s - loss: 0.0235 - 3s/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "2518/2518 - 3s - loss: 0.0233 - 3s/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "2518/2518 - 3s - loss: 0.0230 - 3s/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "2518/2518 - 3s - loss: 0.0228 - 3s/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "2518/2518 - 3s - loss: 0.0220 - 3s/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "2518/2518 - 3s - loss: 0.0221 - 3s/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "2518/2518 - 3s - loss: 0.0215 - 3s/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "2518/2518 - 3s - loss: 0.0216 - 3s/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "2518/2518 - 3s - loss: 0.0213 - 3s/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "2518/2518 - 3s - loss: 0.0210 - 3s/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "2518/2518 - 3s - loss: 0.0206 - 3s/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "2518/2518 - 3s - loss: 0.0204 - 3s/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "2518/2518 - 3s - loss: 0.0204 - 3s/epoch - 1ms/step\n",
      "20/20 [==============================] - 0s 894us/step\n",
      "Root Mean Squared Error (RMSE): 5.96\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Forecast for PolyPwr (Yn+1): 10.22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('Pasion et al dataset.csv')\n",
    "data = df[df['Location'] == 'Hill Weber']\n",
    "data = df[df['Time'] == 1300]\n",
    "\n",
    "data = data[['Date', 'PolyPwr']] \n",
    "data.rename(columns={'Date': 'ds', 'PolyPwr': 'y'}, inplace=True)\n",
    "\n",
    "data['ds'] = pd.to_datetime(data['ds'])\n",
    "data.set_index('ds', inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "look_back = 20  \n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - look_back):\n",
    "    X.append(data_scaled[i:i+look_back])\n",
    "    y.append(data_scaled[i+look_back])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "last_observed = X_test[-1].reshape(1, look_back, 1)\n",
    "\n",
    "forecast_value = model.predict(last_observed)\n",
    "forecast_value = scaler.inverse_transform(forecast_value)[0][0]\n",
    "print(f\"Forecast for PolyPwr (Yn+1): {forecast_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2e8407-f9f2-4b4d-b5b6-9c84a95a68a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2442/2442 - 3s - loss: 0.0393 - 3s/epoch - 1ms/step\n",
      "Epoch 2/100\n",
      "2442/2442 - 3s - loss: 0.0355 - 3s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "2442/2442 - 3s - loss: 0.0354 - 3s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "2442/2442 - 3s - loss: 0.0351 - 3s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "2442/2442 - 3s - loss: 0.0347 - 3s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "2442/2442 - 3s - loss: 0.0348 - 3s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "2442/2442 - 3s - loss: 0.0345 - 3s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "2442/2442 - 3s - loss: 0.0347 - 3s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "2442/2442 - 3s - loss: 0.0346 - 3s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "2442/2442 - 3s - loss: 0.0347 - 3s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "2442/2442 - 3s - loss: 0.0344 - 3s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "2442/2442 - 3s - loss: 0.0346 - 3s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "2442/2442 - 3s - loss: 0.0344 - 3s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "2442/2442 - 3s - loss: 0.0342 - 3s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "2442/2442 - 3s - loss: 0.0342 - 3s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "2442/2442 - 3s - loss: 0.0341 - 3s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "2442/2442 - 3s - loss: 0.0341 - 3s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "2442/2442 - 3s - loss: 0.0341 - 3s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "2442/2442 - 3s - loss: 0.0339 - 3s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "2442/2442 - 3s - loss: 0.0340 - 3s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "2442/2442 - 3s - loss: 0.0340 - 3s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "2442/2442 - 3s - loss: 0.0340 - 3s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "2442/2442 - 3s - loss: 0.0338 - 3s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "2442/2442 - 3s - loss: 0.0338 - 3s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "2442/2442 - 3s - loss: 0.0338 - 3s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "2442/2442 - 3s - loss: 0.0337 - 3s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "2442/2442 - 3s - loss: 0.0336 - 3s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "2442/2442 - 3s - loss: 0.0334 - 3s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "2442/2442 - 3s - loss: 0.0337 - 3s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "2442/2442 - 3s - loss: 0.0334 - 3s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "2442/2442 - 3s - loss: 0.0334 - 3s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "2442/2442 - 3s - loss: 0.0334 - 3s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "2442/2442 - 3s - loss: 0.0331 - 3s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "2442/2442 - 3s - loss: 0.0331 - 3s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "2442/2442 - 3s - loss: 0.0331 - 3s/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "2442/2442 - 3s - loss: 0.0329 - 3s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "2442/2442 - 3s - loss: 0.0328 - 3s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "2442/2442 - 3s - loss: 0.0327 - 3s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "2442/2442 - 3s - loss: 0.0324 - 3s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "2442/2442 - 3s - loss: 0.0324 - 3s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "2442/2442 - 3s - loss: 0.0325 - 3s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "2442/2442 - 3s - loss: 0.0322 - 3s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "2442/2442 - 3s - loss: 0.0323 - 3s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "2442/2442 - 3s - loss: 0.0321 - 3s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "2442/2442 - 3s - loss: 0.0318 - 3s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "2442/2442 - 3s - loss: 0.0318 - 3s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "2442/2442 - 3s - loss: 0.0318 - 3s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "2442/2442 - 3s - loss: 0.0318 - 3s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "2442/2442 - 3s - loss: 0.0315 - 3s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "2442/2442 - 4s - loss: 0.0315 - 4s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "2442/2442 - 3s - loss: 0.0316 - 3s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "2442/2442 - 3s - loss: 0.0309 - 3s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "2442/2442 - 3s - loss: 0.0307 - 3s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "2442/2442 - 3s - loss: 0.0307 - 3s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "2442/2442 - 3s - loss: 0.0306 - 3s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "2442/2442 - 3s - loss: 0.0301 - 3s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "2442/2442 - 3s - loss: 0.0301 - 3s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "2442/2442 - 3s - loss: 0.0298 - 3s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "2442/2442 - 3s - loss: 0.0298 - 3s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "2442/2442 - 3s - loss: 0.0294 - 3s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "2442/2442 - 3s - loss: 0.0294 - 3s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "2442/2442 - 3s - loss: 0.0323 - 3s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "2442/2442 - 3s - loss: 0.0338 - 3s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "2442/2442 - 3s - loss: 0.0327 - 3s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "2442/2442 - 3s - loss: 0.0321 - 3s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "2442/2442 - 3s - loss: 0.0307 - 3s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "2442/2442 - 3s - loss: 0.0296 - 3s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "2442/2442 - 3s - loss: 0.0289 - 3s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "2442/2442 - 3s - loss: 0.0287 - 3s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "2442/2442 - 3s - loss: 0.0285 - 3s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "2442/2442 - 3s - loss: 0.0281 - 3s/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "2442/2442 - 3s - loss: 0.0279 - 3s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "2442/2442 - 3s - loss: 0.0278 - 3s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "2442/2442 - 3s - loss: 0.0274 - 3s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "2442/2442 - 3s - loss: 0.0273 - 3s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "2442/2442 - 3s - loss: 0.0272 - 3s/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "2442/2442 - 4s - loss: 0.0270 - 4s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "2442/2442 - 4s - loss: 0.0271 - 4s/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "2442/2442 - 4s - loss: 0.0262 - 4s/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "2442/2442 - 3s - loss: 0.0264 - 3s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "2442/2442 - 3s - loss: 0.0261 - 3s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "2442/2442 - 3s - loss: 0.0258 - 3s/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "2442/2442 - 3s - loss: 0.0256 - 3s/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "2442/2442 - 3s - loss: 0.0254 - 3s/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "2442/2442 - 3s - loss: 0.0250 - 3s/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "2442/2442 - 3s - loss: 0.0252 - 3s/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "2442/2442 - 3s - loss: 0.0246 - 3s/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "2442/2442 - 3s - loss: 0.0248 - 3s/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "2442/2442 - 3s - loss: 0.0247 - 3s/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "2442/2442 - 3s - loss: 0.0240 - 3s/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "2442/2442 - 3s - loss: 0.0238 - 3s/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "2442/2442 - 3s - loss: 0.0234 - 3s/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "2442/2442 - 104s - loss: 0.0232 - 104s/epoch - 43ms/step\n",
      "Epoch 94/100\n",
      "2442/2442 - 3s - loss: 0.0230 - 3s/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "2442/2442 - 3s - loss: 0.0229 - 3s/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "2442/2442 - 35s - loss: 0.0227 - 35s/epoch - 14ms/step\n",
      "Epoch 97/100\n",
      "2442/2442 - 3s - loss: 0.0224 - 3s/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "2442/2442 - 3s - loss: 0.0228 - 3s/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "2442/2442 - 3s - loss: 0.0235 - 3s/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "2442/2442 - 3s - loss: 0.0216 - 3s/epoch - 1ms/step\n",
      "20/20 [==============================] - 0s 869us/step\n",
      "Root Mean Squared Error (RMSE): 5.87\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Forecast for PolyPwr (Yn+1): 12.54\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('Pasion et al dataset.csv')\n",
    "data = df[df['Location'] == 'Hill Weber']\n",
    "data = df[df['Time'] == 1400]\n",
    "\n",
    "data = data[['Date', 'PolyPwr']] \n",
    "data.rename(columns={'Date': 'ds', 'PolyPwr': 'y'}, inplace=True)\n",
    "\n",
    "data['ds'] = pd.to_datetime(data['ds'])\n",
    "data.set_index('ds', inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "look_back = 20  \n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - look_back):\n",
    "    X.append(data_scaled[i:i+look_back])\n",
    "    y.append(data_scaled[i+look_back])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "last_observed = X_test[-1].reshape(1, look_back, 1)\n",
    "\n",
    "forecast_value = model.predict(last_observed)\n",
    "forecast_value = scaler.inverse_transform(forecast_value)[0][0]\n",
    "print(f\"Forecast for PolyPwr (Yn+1): {forecast_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e683cc3d-72f9-44d2-a10c-8e0babcde244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2562/2562 - 43s - loss: 0.0347 - 43s/epoch - 17ms/step\n",
      "Epoch 2/100\n",
      "2562/2562 - 3s - loss: 0.0333 - 3s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "2562/2562 - 3s - loss: 0.0330 - 3s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "2562/2562 - 42s - loss: 0.0329 - 42s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "2562/2562 - 3s - loss: 0.0329 - 3s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "2562/2562 - 3s - loss: 0.0326 - 3s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "2562/2562 - 3s - loss: 0.0326 - 3s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "2562/2562 - 3s - loss: 0.0325 - 3s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "2562/2562 - 3s - loss: 0.0324 - 3s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "2562/2562 - 3s - loss: 0.0325 - 3s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "2562/2562 - 3s - loss: 0.0323 - 3s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "2562/2562 - 3s - loss: 0.0323 - 3s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "2562/2562 - 1026s - loss: 0.0322 - 1026s/epoch - 401ms/step\n",
      "Epoch 14/100\n",
      "2562/2562 - 3s - loss: 0.0320 - 3s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "2562/2562 - 476s - loss: 0.0322 - 476s/epoch - 186ms/step\n",
      "Epoch 16/100\n",
      "2562/2562 - 3s - loss: 0.0320 - 3s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "2562/2562 - 3s - loss: 0.0319 - 3s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "2562/2562 - 3s - loss: 0.0319 - 3s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "2562/2562 - 3s - loss: 0.0316 - 3s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "2562/2562 - 3s - loss: 0.0318 - 3s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "2562/2562 - 3s - loss: 0.0316 - 3s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "2562/2562 - 3s - loss: 0.0317 - 3s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "2562/2562 - 3s - loss: 0.0317 - 3s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "2562/2562 - 3s - loss: 0.0317 - 3s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "2562/2562 - 3s - loss: 0.0315 - 3s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "2562/2562 - 3s - loss: 0.0314 - 3s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "2562/2562 - 3s - loss: 0.0314 - 3s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "2562/2562 - 3s - loss: 0.0315 - 3s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "2562/2562 - 3s - loss: 0.0313 - 3s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "2562/2562 - 3s - loss: 0.0312 - 3s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "2562/2562 - 3s - loss: 0.0312 - 3s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "2562/2562 - 3s - loss: 0.0310 - 3s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "2562/2562 - 3s - loss: 0.0309 - 3s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "2562/2562 - 3s - loss: 0.0309 - 3s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "2562/2562 - 3s - loss: 0.0309 - 3s/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "2562/2562 - 3s - loss: 0.0308 - 3s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "2562/2562 - 3s - loss: 0.0306 - 3s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "2562/2562 - 3s - loss: 0.0307 - 3s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "2562/2562 - 3s - loss: 0.0304 - 3s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "2562/2562 - 3s - loss: 0.0302 - 3s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "2562/2562 - 3s - loss: 0.0303 - 3s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "2562/2562 - 3s - loss: 0.0302 - 3s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "2562/2562 - 3s - loss: 0.0300 - 3s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "2562/2562 - 3s - loss: 0.0303 - 3s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "2562/2562 - 3s - loss: 0.0301 - 3s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "2562/2562 - 3s - loss: 0.0297 - 3s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "2562/2562 - 3s - loss: 0.0299 - 3s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "2562/2562 - 3s - loss: 0.0298 - 3s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "2562/2562 - 3s - loss: 0.0298 - 3s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "2562/2562 - 3s - loss: 0.0295 - 3s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "2562/2562 - 3s - loss: 0.0292 - 3s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "2562/2562 - 3s - loss: 0.0292 - 3s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "2562/2562 - 3s - loss: 0.0292 - 3s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "2562/2562 - 3s - loss: 0.0290 - 3s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "2562/2562 - 3s - loss: 0.0290 - 3s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "2562/2562 - 3s - loss: 0.0288 - 3s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "2562/2562 - 3s - loss: 0.0286 - 3s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "2562/2562 - 3s - loss: 0.0286 - 3s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "2562/2562 - 3s - loss: 0.0288 - 3s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "2562/2562 - 3s - loss: 0.0284 - 3s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "2562/2562 - 3s - loss: 0.0280 - 3s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "2562/2562 - 3s - loss: 0.0282 - 3s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "2562/2562 - 3s - loss: 0.0277 - 3s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "2562/2562 - 3s - loss: 0.0276 - 3s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "2562/2562 - 3s - loss: 0.0273 - 3s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "2562/2562 - 3s - loss: 0.0272 - 3s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "2562/2562 - 3s - loss: 0.0268 - 3s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "2562/2562 - 3s - loss: 0.0269 - 3s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "2562/2562 - 3s - loss: 0.0265 - 3s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "2562/2562 - 3s - loss: 0.0261 - 3s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "2562/2562 - 3s - loss: 0.0261 - 3s/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "2562/2562 - 3s - loss: 0.0262 - 3s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "2562/2562 - 3s - loss: 0.0257 - 3s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "2562/2562 - 3s - loss: 0.0258 - 3s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "2562/2562 - 3s - loss: 0.0255 - 3s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "2562/2562 - 3s - loss: 0.0252 - 3s/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "2562/2562 - 3s - loss: 0.0247 - 3s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "2562/2562 - 3s - loss: 0.0249 - 3s/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "2562/2562 - 3s - loss: 0.0246 - 3s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "2562/2562 - 3s - loss: 0.0240 - 3s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "2562/2562 - 3s - loss: 0.0241 - 3s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "2562/2562 - 3s - loss: 0.0239 - 3s/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "2562/2562 - 3s - loss: 0.0235 - 3s/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "2562/2562 - 3s - loss: 0.0235 - 3s/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "2562/2562 - 3s - loss: 0.0232 - 3s/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "2562/2562 - 3s - loss: 0.0231 - 3s/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "2562/2562 - 3s - loss: 0.0225 - 3s/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "2562/2562 - 3s - loss: 0.0224 - 3s/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "2562/2562 - 3s - loss: 0.0227 - 3s/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "2562/2562 - 3s - loss: 0.0219 - 3s/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "2562/2562 - 3s - loss: 0.0218 - 3s/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "2562/2562 - 3s - loss: 0.0215 - 3s/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "2562/2562 - 3s - loss: 0.0212 - 3s/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "2562/2562 - 3s - loss: 0.0204 - 3s/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "2562/2562 - 3s - loss: 0.0208 - 3s/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "2562/2562 - 3s - loss: 0.0202 - 3s/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "2562/2562 - 3s - loss: 0.0205 - 3s/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "2562/2562 - 3s - loss: 0.0199 - 3s/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "2562/2562 - 3s - loss: 0.0194 - 3s/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "2562/2562 - 3s - loss: 0.0191 - 3s/epoch - 1ms/step\n",
      "21/21 [==============================] - 0s 870us/step\n",
      "Root Mean Squared Error (RMSE): 5.34\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Forecast for PolyPwr (Yn+1): 10.42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('Pasion et al dataset.csv')\n",
    "data = df[df['Location'] == 'Hill Weber']\n",
    "data = df[df['Time'] == 1500]\n",
    "\n",
    "data = data[['Date', 'PolyPwr']] \n",
    "data.rename(columns={'Date': 'ds', 'PolyPwr': 'y'}, inplace=True)\n",
    "\n",
    "data['ds'] = pd.to_datetime(data['ds'])\n",
    "data.set_index('ds', inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "look_back = 20  \n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - look_back):\n",
    "    X.append(data_scaled[i:i+look_back])\n",
    "    y.append(data_scaled[i+look_back])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "last_observed = X_test[-1].reshape(1, look_back, 1)\n",
    "\n",
    "forecast_value = model.predict(last_observed)\n",
    "forecast_value = scaler.inverse_transform(forecast_value)[0][0]\n",
    "print(f\"Forecast for PolyPwr (Yn+1): {forecast_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265a8c5-9f3e-48cb-b84a-3a0ce6011fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
